{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7b8b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models, callbacks\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dd4cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_dir = './pipeline/cleaned/'\n",
    "\n",
    "cohort = pd.read_csv(read_dir + 'cohort.csv', index_col=0)\n",
    "\n",
    "diag = pd.read_csv(read_dir + 'diag.csv', index_col=0)\n",
    "diag = diag.set_index('hadm_id')\n",
    "\n",
    "labs = pd.read_csv(read_dir + 'labs.csv', index_col=0)\n",
    "labs = labs.set_index('hadm_id')\n",
    "\n",
    "proc = pd.read_csv(read_dir + 'proc.csv', index_col=0)\n",
    "proc = proc.set_index('hadm_id')\n",
    "\n",
    "meds = pd.read_csv(read_dir + 'meds.csv', index_col=0)\n",
    "meds = meds.set_index('hadm_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9163ebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(lr, cohort, diag, labs, proc, meds, use_diag, use_labs, use_proc, use_meds, use_insurance, use_gender, use_race, hf):\n",
    "    if hf:\n",
    "        split = 'split_hf'\n",
    "    else:\n",
    "        split = 'split_diabetes'\n",
    "    train_hadm = cohort[cohort[split]=='train'].hadm_id.to_numpy()\n",
    "    valid_hadm = cohort[cohort[split]=='validation'].hadm_id.to_numpy()\n",
    "    test_hadm = cohort[cohort[split]=='test'].hadm_id.to_numpy()\n",
    "    train_hadm = np.sort(train_hadm)\n",
    "    valid_hadm = np.sort(valid_hadm)\n",
    "    test_hadm = np.sort(test_hadm)\n",
    "    model = Transformer(lr, cohort, diag, labs, proc, meds, use_diag, use_labs, use_proc, use_meds, use_insurance, use_gender, use_race, hf)\n",
    "    print(model.model.summary())\n",
    "    return model, train_hadm, valid_hadm, test_hadm\n",
    "\n",
    "\n",
    "class Transformer(object):\n",
    "    def __init__(self, lr, cohort, diag, labs, proc, meds, use_diag, use_labs, use_proc, use_meds, use_insurance, use_gender, use_race, hf):\n",
    "        keras.backend.clear_session()\n",
    "        physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "        #print(f\"GPU list {physical_devices}\")\n",
    "        #tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "        self.opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "        self.loss = keras.losses.BinaryCrossentropy()\n",
    "        self.metric = keras.metrics.AUC(name='auc')\n",
    "        \n",
    "        self.cohort = cohort\n",
    "        self.diag = diag.copy()\n",
    "        self.labs = labs\n",
    "        self.proc = proc\n",
    "        self.meds = meds\n",
    "        \n",
    "        self.use_diag = use_diag\n",
    "        self.use_labs = use_labs\n",
    "        self.use_proc = use_proc\n",
    "        self.use_meds = use_meds\n",
    "        self.use_insurance = use_insurance\n",
    "        self.use_gender = use_gender\n",
    "        self.use_race = use_race\n",
    "        \n",
    "        self.input_shapes = self.get_input_shapes()\n",
    "        if hf:\n",
    "            self.label = 'label_hf'\n",
    "            self.diag['I50'] = 0\n",
    "        else:\n",
    "            self.label = 'label_diabetes'\n",
    "            self.diag['E11'] = 0\n",
    "         \n",
    "        self.buildModel()\n",
    "    \n",
    "    def embedding(self, inputs):\n",
    "        maxlen = inputs.shape[-2]\n",
    "        varnum = inputs.shape[-1]\n",
    "        pos = keras.backend.arange(start=0, stop=maxlen, step=1)\n",
    "        pos = layers.Embedding(input_dim=maxlen, output_dim=256)(pos)\n",
    "        x = layers.Dense(units=256)(inputs)\n",
    "        return x + pos\n",
    "    \n",
    "    def encoder(self, inputs):\n",
    "        hidden_dim = inputs.shape[-1]\n",
    "        if len(inputs.shape) == 2:\n",
    "            y = layers.Dense(hidden_dim)(inputs)\n",
    "            y = layers.Dropout(0.1)(y)\n",
    "            y = layers.LayerNormalization(epsilon=1e-6)(y)\n",
    "            return tf.expand_dims(y, 1)\n",
    "        \n",
    "        x = layers.MultiHeadAttention(num_heads=8, key_dim=hidden_dim)(inputs, inputs)\n",
    "        x = layers.Dropout(0.1)(x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x + inputs)\n",
    "        \n",
    "        y = layers.Dense(hidden_dim, activation='relu')(x)\n",
    "        y = layers.Dense(hidden_dim)(y)\n",
    "        y = layers.Dropout(0.1)(y)\n",
    "        y = layers.LayerNormalization(epsilon=1e-6)(y + x)\n",
    "        return y\n",
    "    \n",
    "    def buildModel(self): \n",
    "        inputs = [keras.Input(shape=shape) for shape in self.input_shapes]\n",
    "        encoded = [self.encoder(inp) for inp in inputs]\n",
    "        if len(inputs) > 1:\n",
    "            combined = layers.Concatenate(axis=-1)([layers.GlobalAveragePooling1D()(enc) for enc in encoded])\n",
    "        else:\n",
    "            combined = layers.GlobalAveragePooling1D()(encoded[0])\n",
    "        x = layers.Dense(64, activation=\"relu\")(combined)\n",
    "        outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "        self.model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        \n",
    "        self.model.compile(optimizer=self.opt, loss=self.loss, metrics=[self.metric])\n",
    "    \n",
    "    def train(self, train_hadm, valid_hadm, epochs, batchSize, path, val_auc=False, verbose_ckp=1, verbose_fit=2):\n",
    "        if val_auc:\n",
    "            MCP = callbacks.ModelCheckpoint(path, monitor='val_auc', verbose=verbose_ckp, save_best_only=True, mode='max')\n",
    "            ES = callbacks.EarlyStopping(monitor='val_auc', patience=10, verbose=verbose_ckp, mode='max')\n",
    "        else:\n",
    "            MCP = callbacks.ModelCheckpoint(path, monitor='val_loss', verbose=verbose_ckp, save_best_only=True, mode='min') \n",
    "            ES = callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=verbose_ckp, mode='min')\n",
    "        train_gen = self.generator(train_hadm, batchSize)\n",
    "        valid_gen = self.generator(valid_hadm, batchSize)\n",
    "        self.model.fit(train_gen, validation_data=valid_gen, epochs=epochs, verbose=verbose_fit, callbacks=[MCP, ES], \n",
    "                       steps_per_epoch=len(train_hadm)//batchSize, validation_steps=len(valid_hadm)//batchSize)\n",
    "        self.model = models.load_model(path, compile=False)\n",
    "\n",
    "    def load(self, path):\n",
    "        self.model = models.load_model(path, compile=False)\n",
    "        \n",
    "    def predict(self, test_hadm, batchSize, verbose=2):\n",
    "        pred_gen = self.pred_generator(test_hadm, batchSize)\n",
    "        pred = self.model.predict(pred_gen, verbose=verbose, steps=(len(test_hadm)+batchSize-1)//batchSize)\n",
    "        return pred\n",
    "\n",
    "    def generator(self, input_hadm, batchSize):\n",
    "        while 1:\n",
    "            hadm_ids = np.sort(np.random.choice(input_hadm, batchSize, False))\n",
    "            x = self.get_x(hadm_ids, batchSize)\n",
    "            y = self.get_y(hadm_ids)\n",
    "            yield x, y\n",
    "            \n",
    "    def pred_generator(self, input_hadm, batchSize):\n",
    "        i = 0\n",
    "        while 1:\n",
    "            hadm_ids = input_hadm[np.arange(i, min(i+batchSize, len(input_hadm)))]\n",
    "            if i+batchSize >= len(input_hadm):\n",
    "                i = 0\n",
    "            i += len(hadm_ids)\n",
    "            x = self.get_x(hadm_ids, len(hadm_ids))\n",
    "            y = self.get_y(hadm_ids)\n",
    "            yield x, y\n",
    "            \n",
    "    def get_y(self, hadm_ids):\n",
    "        batch_cohort = self.cohort[self.cohort.hadm_id.isin(hadm_ids)].sort_values('hadm_id')\n",
    "        y = batch_cohort[self.label].to_numpy()\n",
    "        return y\n",
    "\n",
    "    def get_input_shapes(self):\n",
    "        xs = []\n",
    "        xd = ( 3, 306)\n",
    "        xl = (14, 107)\n",
    "        xp = ( 2,  18)\n",
    "        xm = (14,  55)\n",
    "    \n",
    "        if self.use_diag:\n",
    "            xs.append(xd)\n",
    "\n",
    "        if self.use_labs:\n",
    "            xs.append(xl)\n",
    "\n",
    "        if self.use_proc:\n",
    "            xs.append(xp)\n",
    "            \n",
    "        if self.use_meds:\n",
    "            xs.append(xm)\n",
    "            \n",
    "        cohort_columns = []\n",
    "        if self.use_insurance:\n",
    "            cohort_columns.append('medicare')\n",
    "            cohort_columns.append('medicaid')\n",
    "        if self.use_gender:\n",
    "            cohort_columns.append('male')\n",
    "        if self.use_race:\n",
    "            cohort_columns.append('white')\n",
    "        if len(cohort_columns) > 0:\n",
    "            xs.append((len(cohort_columns),))\n",
    "\n",
    "        return xs\n",
    "    \n",
    "    def get_x(self, hadm_ids, batchSize):\n",
    "        batch_cohort = self.cohort[self.cohort.hadm_id.isin(hadm_ids)].sort_values('hadm_id')\n",
    "\n",
    "        xs = []\n",
    "        xd = np.zeros((batchSize,  3, 306))\n",
    "        xl = np.zeros((batchSize, 14, 107))\n",
    "        xp = np.zeros((batchSize,  2,  18))\n",
    "        xm = np.zeros((batchSize, 14,  55))\n",
    "\n",
    "        if self.use_diag:\n",
    "            for i in range(batchSize):\n",
    "                seqnum = min(xd.shape[1], batch_cohort.seqnum.iloc[i]+1)\n",
    "                raw_index = batch_cohort.index[i]\n",
    "                xd[i, 0:seqnum] = self.diag.loc[self.cohort[(raw_index-seqnum+1):(raw_index+1)].hadm_id.to_numpy()].to_numpy()\n",
    "            xs.append(xd)\n",
    "\n",
    "        if self.use_labs:\n",
    "            for i in range(batchSize):\n",
    "                hadm_id = hadm_ids[i]\n",
    "                if hadm_id in self.labs.index:\n",
    "                    labs_i = self.labs.loc[hadm_id:hadm_id+1]\n",
    "                    seqnum = min(xl.shape[1], len(labs_i))\n",
    "                    xl[i, 0:seqnum] = labs_i.iloc[-seqnum:].to_numpy()\n",
    "            xs.append(xl)\n",
    "\n",
    "        if self.use_proc:\n",
    "            for i in range(batchSize):\n",
    "                hadm_id = hadm_ids[i]\n",
    "                if hadm_id in self.proc.index:\n",
    "                    proc_i = self.proc.loc[hadm_id:hadm_id+1]\n",
    "                    seqnum = min(xp.shape[1], len(proc_i))\n",
    "                    xp[i, 0:seqnum] = proc_i.iloc[-seqnum:].to_numpy()\n",
    "            xs.append(xp)\n",
    "\n",
    "        if self.use_meds:\n",
    "            for i in range(batchSize):\n",
    "                hadm_id = hadm_ids[i]\n",
    "                if hadm_id in self.meds.index:\n",
    "                    meds_i = self.meds.loc[hadm_id:hadm_id+1]\n",
    "                    seqnum = min(xm.shape[1], len(meds_i))\n",
    "                    xm[i, 0:seqnum] = meds_i.iloc[-seqnum:].to_numpy()\n",
    "            xs.append(xm)\n",
    "\n",
    "        cohort_columns = []\n",
    "        if self.use_insurance:\n",
    "            cohort_columns.append('medicare')\n",
    "            cohort_columns.append('medicaid')\n",
    "        if self.use_gender:\n",
    "            cohort_columns.append('male')\n",
    "        if self.use_race:\n",
    "            cohort_columns.append('white')\n",
    "        if len(cohort_columns) > 0:\n",
    "            xs.append(batch_cohort[cohort_columns].to_numpy())\n",
    "\n",
    "        return xs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a826e510",
   "metadata": {},
   "source": [
    "# All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8e0e32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Settings\n",
    "use_diag = 1\n",
    "use_labs = 1\n",
    "use_proc = 1\n",
    "use_meds = 1\n",
    "use_insurance = 1\n",
    "use_gender = 1\n",
    "use_race = 1\n",
    "hf = 1\n",
    "lr = 1e-3\n",
    "epochs = 100\n",
    "batchSize = 256\n",
    "path='./models/all.h5'\n",
    "\n",
    "# Initialize Model\n",
    "model, train_hadm, valid_hadm, test_hadm = initialize(lr, cohort, diag, labs, proc, meds, use_diag, use_labs, use_proc, use_meds, use_insurance, use_gender, use_race, hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd660bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "model.train(train_hadm, valid_hadm, epochs, batchSize, path, False, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8672f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Results\n",
    "model.load(path)\n",
    "res = model.predict(train_hadm, batchSize, 1)\n",
    "y_true = cohort.set_index('hadm_id').loc[train_hadm].label_hf.to_numpy()\n",
    "roc_auc_score(y_true, res), average_precision_score(y_true, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb959423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Results\n",
    "model.load(path)\n",
    "res = model.predict(valid_hadm, batchSize, 1)\n",
    "y_true = cohort.set_index('hadm_id').loc[valid_hadm].label_hf.to_numpy()\n",
    "roc_auc_score(y_true, res), average_precision_score(y_true, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6f3319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Results\n",
    "model.load(path)\n",
    "res = model.predict(test_hadm, batchSize, 1)\n",
    "y_true = cohort.set_index('hadm_id').loc[test_hadm].label_hf.to_numpy()\n",
    "roc_auc_score(y_true, res), average_precision_score(y_true, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8668b37b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
