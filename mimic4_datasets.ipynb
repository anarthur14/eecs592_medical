{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import psutil\n",
    "from tqdm.auto import tqdm  \n",
    "import dask.dataframe as dd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read admission, diagnosis_icd (icd codes given to each patient each stay), and d_idc_diagnosis (disease name for each code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of admission records in CSV File\n",
      "431231\n"
     ]
    }
   ],
   "source": [
    "# admissions\n",
    "admission=pd.read_csv('admissions.csv', engine='python', on_bad_lines='warn')\n",
    "print(\"The number of admission records in CSV File\")\n",
    "print (len(admission)) #431231"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of diagnoses given to all patients\n",
      "4756326\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ICD codes given to each patient\n",
    "patient_icd_diagnosis=pd.read_csv('diagnoses_icd-2.csv', engine='python', on_bad_lines='warn')\n",
    "print(\"The number of diagnoses given to all patients\")\n",
    "print (len(patient_icd_diagnosis)) #4756326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get counts for each code\n",
    "fruit_counts =patient_icd_diagnosis['icd_code'].value_counts()\n",
    "fruit_counts=fruit_counts.head(20)\n",
    "print(fruit_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of icd_diagnoses\n",
      "109775\n"
     ]
    }
   ],
   "source": [
    "# Disease names for each ICD code\n",
    "disease_icd=pd.read_csv('d_icd_diagnoses.csv', engine='python', on_bad_lines='warn')\n",
    "print(\"The number of icd_diagnoses\")\n",
    "print (len(disease_icd)) #109775"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     icd_code  icd_version                                         long_title\n",
      "2332    25000            9  Diabetes mellitus without mention of complicat...\n"
     ]
    }
   ],
   "source": [
    "#print the disease for each code\n",
    "app=disease_icd[disease_icd['icd_code']=='25000']\n",
    "print(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging & Filtering Some Admissions, ICD codes, and the Diagnosis for each code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# admissions and patient icd codes\n",
    "merge_tables=pd.merge(admission, patient_icd_diagnosis, on=['subject_id', 'hadm_id'], how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Congestive Heart Failure, unspecified = 4280\n",
    "# unspecified essential hypertension = 4019\n",
    "filter_merged_tables=merge_tables[(merge_tables['icd_code']== '4280') | (merge_tables['icd_code']== '25000')] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_values = filter_merged_tables['subject_id']\n",
    "\n",
    "print(\"Distinct values in the column:\")\n",
    "print(len(distinct_values))\n",
    "\n",
    "print(filter_merged_tables[['subject_id', 'hadm_id', 'icd_code']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle\n",
    "shuffled_df =filter_merged_tables.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(\"Shuffled DataFrame:\")\n",
    "print(shuffled_df[['subject_id', 'hadm_id', 'icd_code']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disease names for each code\n",
    "filters_tables=pd.merge(filter_merged_tables, disease_icd, on=['icd_code', 'icd_version'], how='inner')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading lab events and presciption files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 252/253 [00:00<00:00, 50757.04block/s]\n"
     ]
    }
   ],
   "source": [
    "# Prescriptions-read the dataset using dask  Row count=15416708\n",
    "prescriptions_path = 'prescriptions.csv'\n",
    "\n",
    "options={'dose_val_rx': 'object',\n",
    "       'form_rx': 'object',\n",
    "       'form_val_disp': 'object',\n",
    "       'gsn': 'object',\n",
    "       'ndc': 'float64',\n",
    "       'poe_seq': 'float64'}\n",
    "\n",
    "\n",
    "\n",
    "file_size = os.path.getsize(prescriptions_path)\n",
    "\n",
    "# Set the desired block size for reading the file\n",
    "# You can adjust this value based on the size of your file and available memory\n",
    "block_size = 10 * 1024 * 1024  # 10 MB\n",
    "\n",
    "# Calculate the total number of blocks\n",
    "total_blocks = (file_size + block_size - 1) // block_size\n",
    "\n",
    "with tqdm(total=total_blocks, unit='block') as pbar:\n",
    "    prescriptions = dd.read_csv(prescriptions_path, blocksize=block_size, dtype=options)\n",
    "    for _ in prescriptions.to_delayed():\n",
    "        pbar.update(1)\n",
    "#print(len(prescriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_id   hadm_id            admittime            dischtime deathtime  \\\n",
      "0    10000635  26134563  2136-06-19 14:24:00  2136-06-20 11:30:00      <NA>   \n",
      "1    10000635  26134563  2136-06-19 14:24:00  2136-06-20 11:30:00      <NA>   \n",
      "\n",
      "           admission_type admit_provider_id admission_location  \\\n",
      "0  AMBULATORY OBSERVATION            P611A0     PROCEDURE SITE   \n",
      "1  AMBULATORY OBSERVATION            P611A0     PROCEDURE SITE   \n",
      "\n",
      "  discharge_location insurance  ...     gsn           ndc    prod_strength  \\\n",
      "0               <NA>     Other  ...  041660  5.539000e+10         1mg Vial   \n",
      "1               <NA>     Other  ...  001275  2.450041e+08  10mEq ER Tablet   \n",
      "\n",
      "  form_rx dose_val_rx  dose_unit_rx  form_val_disp form_unit_disp  \\\n",
      "0     NaN           1            mg              1           VIAL   \n",
      "1     NaN          20           mEq              2            TAB   \n",
      "\n",
      "   doses_per_24_hrs route  \n",
      "0               NaN    IM  \n",
      "1               NaN    PO  \n",
      "\n",
      "[2 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "#print(prescriptions.head(2))\n",
    "prescription_merged=dd.merge(filters_tables, prescriptions, on=['subject_id', 'hadm_id'], how='inner')\n",
    "print(prescription_merged.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1309/1310 [00:00<00:00, 50918.55block/s]\n"
     ]
    }
   ],
   "source": [
    "# Lab Events-read the dataset using dask  Row count=118171367\n",
    "labevents_path = 'labevents.csv'\n",
    "\n",
    "file_size = os.path.getsize(labevents_path)\n",
    "\n",
    "# Set the desired block size for reading the file\n",
    "# You can adjust this value based on the size of your file and available memory\n",
    "block_size = 10 * 1024 * 1024  # 10 MB\n",
    "\n",
    "# Calculate the total number of blocks\n",
    "total_blocks = (file_size + block_size - 1) // block_size\n",
    "\n",
    "with tqdm(total=total_blocks, unit='block') as pbar:\n",
    "    labevents = dd.read_csv(labevents_path, blocksize=block_size)\n",
    "    for _ in labevents.to_delayed():\n",
    "        pbar.update(1)\n",
    "#labevents = labevents.dropna(subset=['hadm_id'])\n",
    "\n",
    "#labevents['hadm_id']=labevents['hadm_id'].astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/dask/dataframe/multi.py:520: UserWarning: Merging dataframes with merge column data type mismatches: \n",
      "+------------------------+------------+-------------+\n",
      "| Merge columns          | left dtype | right dtype |\n",
      "+------------------------+------------+-------------+\n",
      "| ('hadm_id', 'hadm_id') | int64      | float64     |\n",
      "+------------------------+------------+-------------+\n",
      "Cast dtypes explicitly to avoid unexpected results.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "labevents_merged=dd.merge(prescription_merged, labevents, on=['subject_id', 'hadm_id'], how='inner')\n",
    "# print(labevents_merged.columns)\n",
    "# print(labevents_merged.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   labevent_id  subject_id  hadm_id  specimen_id  itemid order_provider_id  \\\n",
      "0            1    10000032      NaN     45421181   51237            P28Z0X   \n",
      "1            2    10000032      NaN     45421181   51274            P28Z0X   \n",
      "\n",
      "             charttime            storetime value  valuenum valueuom  \\\n",
      "0  2180-03-23 11:51:00  2180-03-23 15:15:00   1.4       1.4      NaN   \n",
      "1  2180-03-23 11:51:00  2180-03-23 15:15:00   ___      15.1      sec   \n",
      "\n",
      "   ref_range_lower  ref_range_upper      flag priority   comments  \n",
      "0              0.9              1.1  abnormal  ROUTINE        NaN  \n",
      "1              9.4             12.5  abnormal  ROUTINE  VERIFIED.  \n"
     ]
    }
   ],
   "source": [
    "print(labevents.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "252block [00:00, 35243.90block/s]       \n"
     ]
    }
   ],
   "source": [
    "# D_labitems-read the dataset using dask  Row count=1622\n",
    "d_labitems_path = 'd_labitems.csv'\n",
    "\n",
    "file_size = os.path.getsize(d_labitems_path)\n",
    "\n",
    "# Set the desired block size for reading the file\n",
    "# You can adjust this value based on the size of your file and available memory\n",
    "block_size = 10 * 1024 * 1024  # 10 MB\n",
    "\n",
    "# Calculate the total number of blocks\n",
    "total_blocks = (file_size + block_size - 1) // block_size\n",
    "\n",
    "with tqdm(total=total_blocks, unit='block') as pbar:\n",
    "    d_labitems = dd.read_csv(d_labitems_path, blocksize=block_size)\n",
    "    for _ in prescriptions.to_delayed():\n",
    "        pbar.update(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged labitems\n",
    "\n",
    "labitems_merged=dd.merge(labevents_merged, d_labitems, on=['itemid'], how='inner')\n",
    "#print(labitems_merged.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(labitems_merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of rows in the Dask DataFrame\n",
    "num_rows = labitems_merged.map_partitions(len).sum().compute()\n",
    "\n",
    "print(\"Number of rows:\", num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove unneccessary columns\n",
    "columns_drop=['deathtime','hospital_expire_flag','seq_num','icd_version','order_provider_id_x','admit_provider_id', 'poe_id', 'poe_seq', 'starttime', 'stoptime', 'order_provider_id_y']\n",
    "mimic_table = labitems_merged.drop(columns_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Race\n",
    "columns_drop=['race']\n",
    "\n",
    "mimic_table_NO_race=labitems_merged.drop(columns_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Insurance\n",
    "columns_drop=['insurance']\n",
    "\n",
    "mimic_table_NO_insurance=labitems_merged.drop(columns_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove both insurance and race\n",
    "columns_drop=['race', 'insurance']\n",
    "\n",
    "mimic_table_NO_race_insurance=labitems_merged.drop(columns_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE CSV FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of both diseases in the first 20K\n",
    "first_20k_rows = labitems_merged.head(20000)\n",
    "diabetes = (first_20k_rows['icd_code'] == '25000').sum()\n",
    "print(\"Number of patients with diabetes in first 20,000 rows:\", diabetes)\n",
    "congestive=  (first_20k_rows['icd_code'] == '4280').sum()\n",
    "print(\"Number of patients with congestive heart failure in the first 20,000 rows:\", congestive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[235], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m     end_index \u001b[38;5;241m=\u001b[39m start_index \u001b[38;5;241m+\u001b[39m size\n\u001b[1;32m      8\u001b[0m     partition \u001b[38;5;241m=\u001b[39m mimic_table_NO_race_insurance\u001b[38;5;241m.\u001b[39mpartitions[start_index:end_index]\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mpartition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMIMIC_IV_NoBias\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msize\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     start_index \u001b[38;5;241m=\u001b[39m end_index\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiles Saved\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/dask_expr/_collection.py:2296\u001b[0m, in \u001b[0;36mFrameBase.to_csv\u001b[0;34m(self, filename, **kwargs)\u001b[0m\n\u001b[1;32m   2293\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See dd.to_csv docstring for more information\"\"\"\u001b[39;00m\n\u001b[1;32m   2294\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask_expr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcsv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_csv\n\u001b[0;32m-> 2296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/dask_expr/io/csv.py:141\u001b[0m, in \u001b[0;36mto_csv\u001b[0;34m(df, filename, single_file, encoding, mode, name_function, compression, compute, scheduler, storage_options, header_first_partition_only, compute_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_csv\u001b[39m(\n\u001b[1;32m    124\u001b[0m     df,\n\u001b[1;32m    125\u001b[0m     filename,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcsv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_csv \u001b[38;5;28;01mas\u001b[39;00m _to_csv\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _to_csv(\n\u001b[0;32m--> 141\u001b[0m         \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dask_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    142\u001b[0m         filename,\n\u001b[1;32m    143\u001b[0m         single_file\u001b[38;5;241m=\u001b[39msingle_file,\n\u001b[1;32m    144\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m    145\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    146\u001b[0m         name_function\u001b[38;5;241m=\u001b[39mname_function,\n\u001b[1;32m    147\u001b[0m         compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m    148\u001b[0m         compute\u001b[38;5;241m=\u001b[39mcompute,\n\u001b[1;32m    149\u001b[0m         scheduler\u001b[38;5;241m=\u001b[39mscheduler,\n\u001b[1;32m    150\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    151\u001b[0m         header_first_partition_only\u001b[38;5;241m=\u001b[39mheader_first_partition_only,\n\u001b[1;32m    152\u001b[0m         compute_kwargs\u001b[38;5;241m=\u001b[39mcompute_kwargs,\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    154\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/dask_expr/_collection.py:1258\u001b[0m, in \u001b[0;36mFrameBase.to_dask_dataframe\u001b[0;34m(self, optimize, **optimize_kwargs)\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_dask_dataframe\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimize: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptimize_kwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _Frame:\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert to a dask-dataframe collection\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m \n\u001b[1;32m   1251\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;124;03m        Key-word arguments to pass through to `optimize`.\u001b[39;00m\n\u001b[1;32m   1257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1258\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptimize_kwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m optimize \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_dd_object(df\u001b[38;5;241m.\u001b[39mdask, df\u001b[38;5;241m.\u001b[39m_name, df\u001b[38;5;241m.\u001b[39m_meta, df\u001b[38;5;241m.\u001b[39mdivisions)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/dask_expr/_collection.py:488\u001b[0m, in \u001b[0;36mFrameBase.optimize\u001b[0;34m(self, fuse)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\u001b[38;5;28mself\u001b[39m, fuse: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_collection(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuse\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/dask_expr/_expr.py:93\u001b[0m, in \u001b[0;36mExpr.optimize\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/dask_expr/_expr.py:2877\u001b[0m, in \u001b[0;36moptimize\u001b[0;34m(expr, fuse)\u001b[0m\n\u001b[1;32m   2856\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"High level query optimization\u001b[39;00m\n\u001b[1;32m   2857\u001b[0m \n\u001b[1;32m   2858\u001b[0m \u001b[38;5;124;03mThis leverages three optimization passes:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2873\u001b[0m \u001b[38;5;124;03moptimize_blockwise_fusion\u001b[39;00m\n\u001b[1;32m   2874\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2875\u001b[0m stage: core\u001b[38;5;241m.\u001b[39mOptimizerStage \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fuse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimplified-physical\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 2877\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimize_until\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/dask_expr/_expr.py:2843\u001b[0m, in \u001b[0;36moptimize_until\u001b[0;34m(expr, stage)\u001b[0m\n\u001b[1;32m   2840\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m expr\n\u001b[1;32m   2842\u001b[0m \u001b[38;5;66;03m# Simplify again\u001b[39;00m\n\u001b[0;32m-> 2843\u001b[0m expr \u001b[38;5;241m=\u001b[39m \u001b[43mexpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimplify\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2844\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stage \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimplified-physical\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2845\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m expr\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/dask_expr/_core.py:371\u001b[0m, in \u001b[0;36mExpr.simplify\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     dependents \u001b[38;5;241m=\u001b[39m collect_dependents(expr)\n\u001b[0;32m--> 371\u001b[0m     new \u001b[38;5;241m=\u001b[39m \u001b[43mexpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimplify_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdependents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdependents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimplified\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m==\u001b[39m expr\u001b[38;5;241m.\u001b[39m_name:\n\u001b[1;32m    373\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/dask_expr/_core.py:322\u001b[0m, in \u001b[0;36mExpr.simplify_once\u001b[0;34m(self, dependents, simplified)\u001b[0m\n\u001b[1;32m    319\u001b[0m expr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 322\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mexpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_simplify_down\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m         out \u001b[38;5;241m=\u001b[39m expr\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/dask_expr/_expr.py:1961\u001b[0m, in \u001b[0;36mProjection._simplify_down\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1959\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_simplify_down\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1960\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m-> 1961\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m   1962\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_meta\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe\u001b[38;5;241m.\u001b[39m_meta\u001b[38;5;241m.\u001b[39mndim\n\u001b[1;32m   1963\u001b[0m     ):\n\u001b[1;32m   1964\u001b[0m         \u001b[38;5;66;03m# TODO: we should get more precise around Expr.columns types\u001b[39;00m\n\u001b[1;32m   1965\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe\n\u001b[1;32m   1966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe, Projection):\n\u001b[1;32m   1967\u001b[0m         \u001b[38;5;66;03m# df[a][b]\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/dask_expr/_expr.py:402\u001b[0m, in \u001b[0;36mExpr.columns\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcolumns\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 402\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_meta\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/functools.py:1001\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    999\u001b[0m val \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[0;32m-> 1001\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1002\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1003\u001b[0m         cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname] \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/dask_expr/_expr.py:2692\u001b[0m, in \u001b[0;36mPartitions._meta\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2690\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcached_property\n\u001b[1;32m   2691\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_meta\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 2692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_meta\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/functools.py:1001\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    999\u001b[0m val \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[0;32m-> 1001\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1002\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1003\u001b[0m         cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname] \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/dask_expr/_merge.py:177\u001b[0m, in \u001b[0;36mMerge._meta\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcached_property\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_meta\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 177\u001b[0m     left \u001b[38;5;241m=\u001b[39m meta_nonempty(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_meta\u001b[49m)\n\u001b[1;32m    178\u001b[0m     right \u001b[38;5;241m=\u001b[39m meta_nonempty(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright\u001b[38;5;241m.\u001b[39m_meta)\n\u001b[1;32m    179\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/functools.py:1001\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    999\u001b[0m val \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[0;32m-> 1001\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1002\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1003\u001b[0m         cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname] \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/dask_expr/_merge.py:177\u001b[0m, in \u001b[0;36mMerge._meta\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcached_property\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_meta\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 177\u001b[0m     left \u001b[38;5;241m=\u001b[39m \u001b[43mmeta_nonempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_meta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     right \u001b[38;5;241m=\u001b[39m meta_nonempty(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright\u001b[38;5;241m.\u001b[39m_meta)\n\u001b[1;32m    179\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/dask/utils.py:773\u001b[0m, in \u001b[0;36mDispatch.__call__\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;124;03mCall the corresponding method based on type of argument.\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    772\u001b[0m meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch(\u001b[38;5;28mtype\u001b[39m(arg))\n\u001b[0;32m--> 773\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/dask/dataframe/backends.py:352\u001b[0m, in \u001b[0;36mmeta_nonempty_dataframe\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    350\u001b[0m         dt_s_dict[dt] \u001b[38;5;241m=\u001b[39m _nonempty_series(x\u001b[38;5;241m.\u001b[39miloc[:, i], idx\u001b[38;5;241m=\u001b[39midx)\n\u001b[1;32m    351\u001b[0m     data[i] \u001b[38;5;241m=\u001b[39m dt_s_dict[dt]\n\u001b[0;32m--> 352\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m res\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m    354\u001b[0m res\u001b[38;5;241m.\u001b[39mattrs \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mattrs\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/frame.py:736\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    730\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    731\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    732\u001b[0m     )\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 736\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/internals/construction.py:443\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mseries\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Series\n\u001b[0;32m--> 443\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m \u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m     missing \u001b[38;5;241m=\u001b[39m arrays\u001b[38;5;241m.\u001b[39misna()\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;66;03m# GH10856\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;66;03m# raise ValueError if only scalars in dict\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/series.py:475\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    473\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39m_mgr\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_dict_like(data):\n\u001b[0;32m--> 475\u001b[0m     data, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    477\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/series.py:568\u001b[0m, in \u001b[0;36mSeries._init_dict\u001b[0;34m(self, data, index, dtype)\u001b[0m\n\u001b[1;32m    565\u001b[0m     keys, values \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;241m0\u001b[39m), []\n\u001b[1;32m    567\u001b[0m \u001b[38;5;66;03m# Input is now list-like, so rely on \"standard\" construction:\u001b[39;00m\n\u001b[0;32m--> 568\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;66;03m# Now we just make sure the order is respected, if any\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/series.py:512\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    510\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 512\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    514\u001b[0m     manager \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/construction.py:628\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    625\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 628\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m \u001b[43m_try_cast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m maybe_convert_platform(data)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/construction.py:767\u001b[0m, in \u001b[0;36m_try_cast\u001b[0;34m(arr, dtype, copy)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_ndarray:\n\u001b[0;32m--> 767\u001b[0m         subarr \u001b[38;5;241m=\u001b[39m \u001b[43mconstruct_1d_object_array_from_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m subarr\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ensure_wrapped_if_datetimelike(arr)\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/dtypes/cast.py:1565\u001b[0m, in \u001b[0;36mconstruct_1d_object_array_from_listlike\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;66;03m# numpy will try to interpret nested lists as further dimensions, hence\u001b[39;00m\n\u001b[1;32m   1563\u001b[0m \u001b[38;5;66;03m# making a 1D array that contains list-likes is a bit tricky:\u001b[39;00m\n\u001b[1;32m   1564\u001b[0m result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mlen\u001b[39m(values), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1565\u001b[0m \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m values\n\u001b[1;32m   1566\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/series.py:953\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    907\u001b[0m \u001b[38;5;124;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;124;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    952\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m--> 953\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(values, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m    955\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mview()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/arrays/arrow/array.py:595\u001b[0m, in \u001b[0;36mArrowExtensionArray.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: NpDtype \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    594\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Correctly construct numpy arrays when passed to `np.asarray()`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 595\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/arrays/arrow/array.py:1285\u001b[0m, in \u001b[0;36mArrowExtensionArray.to_numpy\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hasna:\n\u001b[0;32m-> 1285\u001b[0m     result[\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misna\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m] \u001b[38;5;241m=\u001b[39m na_value\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/arrays/arrow/array.py:749\u001b[0m, in \u001b[0;36mArrowExtensionArray.isna\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m null_count \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n\u001b[0;32m--> 749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pa_array\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_null\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_numpy()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#EVERTHYING - BIAS\n",
    "partition_sizes = [20000, 15000, 5000]\n",
    "\n",
    "# Save partitions to separate files\n",
    "start_index = 0\n",
    "for i, size in enumerate(partition_sizes):\n",
    "    end_index = start_index + size\n",
    "    partition = mimic_table_NO_race_insurance.partitions[start_index:end_index]\n",
    "    partition.to_csv(f'MIMIC_IV_NoBias{size}.csv', index=False)\n",
    "    start_index = end_index\n",
    "print(\"Files Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVERTHYING WITH BOTH BIAS\n",
    "partition_sizes = [20000, 15000, 5000]\n",
    "\n",
    "# Save partitions to separate files\n",
    "start_index = 0\n",
    "for i, size in enumerate(partition_sizes):\n",
    "    end_index = start_index + size\n",
    "    partition = mimic_table.partitions[start_index:end_index]\n",
    "    partition.to_csv(f'MIMIC_IV_WithBias{size}.csv', index=False)\n",
    "    start_index = end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVERTHYING + INSURANCE\n",
    "partition_sizes = [20000, 15000, 5000]\n",
    "\n",
    "# Save partitions to separate files\n",
    "start_index = 0\n",
    "for i, size in enumerate(partition_sizes):\n",
    "    end_index = start_index + size\n",
    "    partition = mimic_table_NO_race.partitions[start_index:end_index]\n",
    "    partition.to_csv(f'MIMIC_IV_Insurance{size}.csv', index=False)\n",
    "    start_index = end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVERTHYING + RACE\n",
    "partition_sizes = [20000, 15000, 5000]\n",
    "\n",
    "# Save partitions to separate files\n",
    "start_index = 0\n",
    "for i, size in enumerate(partition_sizes):\n",
    "    end_index = start_index + size\n",
    "    partition = mimic_table_NO_insurance.partitions[start_index:end_index]\n",
    "    partition.to_csv(f'MIMIC_IV_Race{size}.csv', index=False)\n",
    "    start_index = end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved.\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "# Train - First 20,000 rows. Save to CSV File\n",
    "train_records=labitems_merged.head(40)\n",
    "#train_records.loc[:,'DIAGNOSIS']=train_records['DIAGNOSIS'].apply(lambda a: a if a in most_common else 'Other')\n",
    "train_records.to_csv('MIMIC_IV_train.csv', index=False) \n",
    "print(\"File saved.\") \n",
    "print(len(train_records))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation - 10,000 rows. Save to CSV File\n",
    "validation_records=merge_tables.iloc[20000:30000]\n",
    "#validation_records.loc[:,'DIAGNOSIS']=validation_records['DIAGNOSIS'].apply(lambda a: a if a in most_common else 'Other')\n",
    "validation_records.to_csv('MIMIC_IV_validation.csv', index=False)\n",
    "print(\"File saved\")\n",
    "print(len(validation_records))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test - 5,000 rows. Save to CSV File\n",
    "test_records=merge_tables.iloc[30000:35000]\n",
    "#test_records.loc[:,'DIAGNOSIS']=test_records['DIAGNOSIS'].apply(lambda a: a if a in most_common else 'Other')\n",
    "test_records.to_csv('MIMIC_IV_validation.csv', index=False)\n",
    "print(\"File saved\")\n",
    "print(len(test_records))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
